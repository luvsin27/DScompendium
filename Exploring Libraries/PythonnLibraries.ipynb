{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Overview of Numpy,Pandas,Geopandas,Matplotlib,Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python vs Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of numpy library has been extenisively documented in [Numpy User Guide](https://docs.scipy.org/doc/numpy/user/index.html).lets try to establish why it is needed for numerical computing by comparing them it with python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Python array.png\" alt=\"Python array\" align=\"left\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python does have a inherent array module .It has a list object that behave essentially behaves like an array,that have the same data type for their elements. This can be convenient in applications that don’t need to be concerned with all the ways data can be represented in a compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"numpy array.png\" alt=\"numpy array\" align=\"left\"></img> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy provides an N-dimensional array type, the ndarray, which describes a collection of “items” of the same type. The items can be indexed using for example N integers.\n",
    "\n",
    "All ndarrays are homogenous: every item takes up the same size block of memory, and all blocks are interpreted in exactly the same way. How each item in the array is to be interpreted is specified by a separate data-type object, one of which is associated with every array. In addition to basic types (integers, floats, etc.), the data type objects can also represent data structures.\n",
    "\n",
    "An item extracted from an array, e.g., by indexing, is represented by a Python object whose type is one of the array scalar types built in NumPy. The array scalars allow easy manipulation of also more complicated arrangements of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyArray Object \n",
    "\n",
    "<img src=\"numpy.png\" alt=\"numpy array\" align=\"left\"></img>\n",
    "<img src=\"PyArrayObj.png\" alt=\"PyArrayObj\" align=\"middle\"></img> \n",
    "\n",
    "source [scipy docs](https://docs.scipy.org/doc/numpy-1.15.0/reference/c-api.types-and-structures.html#c.PyArrayObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "gso= sys.getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=list(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gso(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gso([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gso(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1096"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gso(lst)+gso(gso(x) for x in lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr=np.arange(100,dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gso(np.array([],dtype='int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gso(np_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100,), <memory at 0x7f3d5c108c48>, (4,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr.shape,np_arr.data,np_arr.strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603 ns ± 3.66 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit sum(np_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2, 4, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((2, 3), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
       "       [0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
       "       [0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
       "       [0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
       "       [0, 1, 2, 0, 1, 2, 0, 1, 2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(np.arange(3), (5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat([1, 2],[5,3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.44444444, 1.88888889, 2.33333333, 2.77777778,\n",
       "       3.22222222, 3.66666667, 4.11111111, 4.55555556, 5.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(1, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix('1, 2; 3, 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "structured array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([('a', 0.8), ('b', 0.2)], dtype=[('label', 'a8'), ('prob', 'f8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'a', b'b'], dtype='|S8')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8, 0.2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['prob']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy's broadcasting allows us to vectorize operations like addition, subtraction etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2, 4, 6])\n",
    "b = np.array([8, 10, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 14, 18])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 7])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7, -5, -3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 40, 60])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting vectorizes the operation so that it's as if the scalars 1, 9 and 10 we're repeated to form an array with the same dimensions as a to allow the operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rules for Numpy broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from the Numpy documentation - <br>\n",
    "When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing dimensions, and works its way forward. Two dimensions are compatible when\n",
    "\n",
    "* they are equal, or\n",
    "* one of them is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(100).reshape(20, 5)\n",
    "b = np.arange(20).reshape(20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3,   4],\n",
       "       [  6,   7,   8,   9,  10],\n",
       "       [ 12,  13,  14,  15,  16],\n",
       "       [ 18,  19,  20,  21,  22],\n",
       "       [ 24,  25,  26,  27,  28],\n",
       "       [ 30,  31,  32,  33,  34],\n",
       "       [ 36,  37,  38,  39,  40],\n",
       "       [ 42,  43,  44,  45,  46],\n",
       "       [ 48,  49,  50,  51,  52],\n",
       "       [ 54,  55,  56,  57,  58],\n",
       "       [ 60,  61,  62,  63,  64],\n",
       "       [ 66,  67,  68,  69,  70],\n",
       "       [ 72,  73,  74,  75,  76],\n",
       "       [ 78,  79,  80,  81,  82],\n",
       "       [ 84,  85,  86,  87,  88],\n",
       "       [ 90,  91,  92,  93,  94],\n",
       "       [ 96,  97,  98,  99, 100],\n",
       "       [102, 103, 104, 105, 106],\n",
       "       [108, 109, 110, 111, 112],\n",
       "       [114, 115, 116, 117, 118]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some broadcasting exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((9, 8, 1, 3, 3))\n",
    "b = np.ones((1, 8, 9, 1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can they be broadcasted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "\n",
       "       [[[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]]]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((9, 1, 1))\n",
    "b = np.ones((1, 9, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can they be broadcasted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]],\n",
       "\n",
       "       [[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]],\n",
       "\n",
       "       [[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]],\n",
       "\n",
       "       [[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]],\n",
       "\n",
       "       [[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]],\n",
       "\n",
       "       [[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]],\n",
       "\n",
       "       [[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]],\n",
       "\n",
       "       [[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]],\n",
       "\n",
       "       [[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Added a new example\n",
    "a = np.ones((9, 1, 2))\n",
    "b = np.ones((1, 9, 2))\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25,)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(25)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0],\n",
       "       [ 1],\n",
       "       [ 2],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 5],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [11],\n",
       "       [12],\n",
       "       [13],\n",
       "       [14],\n",
       "       [15],\n",
       "       [16],\n",
       "       [17],\n",
       "       [18],\n",
       "       [19],\n",
       "       [20],\n",
       "       [21],\n",
       "       [22],\n",
       "       [23],\n",
       "       [24]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(50).reshape(5, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 41],\n",
       "       [42, 43],\n",
       "       [44, 45],\n",
       "       [46, 47],\n",
       "       [48, 49]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1,...,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 11],\n",
       "       [12, 13],\n",
       "       [14, 15],\n",
       "       [16, 17],\n",
       "       [18, 19]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1, :5, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5],\n",
       "        [ 6,  7],\n",
       "        [ 8,  9]],\n",
       "\n",
       "       [[10, 11],\n",
       "        [12, 13],\n",
       "        [14, 15],\n",
       "        [16, 17],\n",
       "        [18, 19]],\n",
       "\n",
       "       [[20, 21],\n",
       "        [22, 23],\n",
       "        [24, 25],\n",
       "        [26, 27],\n",
       "        [28, 29]],\n",
       "\n",
       "       [[30, 31],\n",
       "        [32, 33],\n",
       "        [34, 35],\n",
       "        [36, 37],\n",
       "        [38, 39]],\n",
       "\n",
       "       [[40, 41],\n",
       "        [42, 43],\n",
       "        [44, 45],\n",
       "        [46, 47],\n",
       "        [48, 49]]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  1]],\n",
       "\n",
       "        [[ 2,  3]],\n",
       "\n",
       "        [[ 4,  5]],\n",
       "\n",
       "        [[ 6,  7]],\n",
       "\n",
       "        [[ 8,  9]]],\n",
       "\n",
       "\n",
       "       [[[10, 11]],\n",
       "\n",
       "        [[12, 13]],\n",
       "\n",
       "        [[14, 15]],\n",
       "\n",
       "        [[16, 17]],\n",
       "\n",
       "        [[18, 19]]],\n",
       "\n",
       "\n",
       "       [[[20, 21]],\n",
       "\n",
       "        [[22, 23]],\n",
       "\n",
       "        [[24, 25]],\n",
       "\n",
       "        [[26, 27]],\n",
       "\n",
       "        [[28, 29]]],\n",
       "\n",
       "\n",
       "       [[[30, 31]],\n",
       "\n",
       "        [[32, 33]],\n",
       "\n",
       "        [[34, 35]],\n",
       "\n",
       "        [[36, 37]],\n",
       "\n",
       "        [[38, 39]]],\n",
       "\n",
       "\n",
       "       [[[40, 41]],\n",
       "\n",
       "        [[42, 43]],\n",
       "\n",
       "        [[44, 45]],\n",
       "\n",
       "        [[46, 47]],\n",
       "\n",
       "        [[48, 49]]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5],\n",
       "        [ 6,  7],\n",
       "        [ 8,  9]],\n",
       "\n",
       "       [[10, 11],\n",
       "        [12, 13],\n",
       "        [14, 15],\n",
       "        [16, 17],\n",
       "        [18, 19]],\n",
       "\n",
       "       [[20, 21],\n",
       "        [22, 23],\n",
       "        [24, 25],\n",
       "        [26, 27],\n",
       "        [28, 29]],\n",
       "\n",
       "       [[30, 31],\n",
       "        [32, 33],\n",
       "        [34, 35],\n",
       "        [36, 37],\n",
       "        [38, 39]],\n",
       "\n",
       "       [[40, 41],\n",
       "        [42, 43],\n",
       "        [44, 45],\n",
       "        [46, 47],\n",
       "        [48, 49]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [12, 13],\n",
       "       [24, 25],\n",
       "       [36, 37],\n",
       "       [48, 49]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[[0, 1, 2, 3, 4], [0, 1, 2, 3, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1]\n",
      "  [2 3]\n",
      "  [4 5]\n",
      "  [6 7]\n",
      "  [8 9]]]\n"
     ]
    }
   ],
   "source": [
    "x = a[0:1,...].copy()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   1   2   3   4]\n",
      " [  5   6   7   8   9]]\n"
     ]
    }
   ],
   "source": [
    "x[0, 0] = 100\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What will the output of this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  4],\n",
       "       [11, 13, 14],\n",
       "       [21, 23, 24]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[::2, [1, 3, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "What if you wanted to access elements in a cross product manner? <br>\n",
    "eg. (0, 0), (0, 2), (0, 3), (2, 0), (2, 2), (2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [2]]), array([[0, 2, 3]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ix_([0, 2], [0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2,  3],\n",
       "       [10, 12, 13]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[np.ix_([0, 2], [0, 2, 3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exerise time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(25).reshape((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.arange(75).reshape((5, 5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]]\n",
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]\n",
      "  [ 9 10 11]\n",
      "  [12 13 14]]\n",
      "\n",
      " [[15 16 17]\n",
      "  [18 19 20]\n",
      "  [21 22 23]\n",
      "  [24 25 26]\n",
      "  [27 28 29]]\n",
      "\n",
      " [[30 31 32]\n",
      "  [33 34 35]\n",
      "  [36 37 38]\n",
      "  [39 40 41]\n",
      "  [42 43 44]]\n",
      "\n",
      " [[45 46 47]\n",
      "  [48 49 50]\n",
      "  [51 52 53]\n",
      "  [54 55 56]\n",
      "  [57 58 59]]\n",
      "\n",
      " [[60 61 62]\n",
      "  [63 64 65]\n",
      "  [66 67 68]\n",
      "  [69 70 71]\n",
      "  [72 73 74]]]\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n",
      "(5, 5, 3)\n",
      "(5, 5, 1)\n",
      "(5, 5, 3)\n",
      "(5, 3, 2)\n",
      "[[[ 0  2]\n",
      "  [ 8 10]\n",
      "  [16 18]]\n",
      "\n",
      " [[20 22]\n",
      "  [28 30]\n",
      "  [36 38]]\n",
      "\n",
      " [[40 42]\n",
      "  [48 50]\n",
      "  [56 58]]\n",
      "\n",
      " [[60 62]\n",
      "  [68 70]\n",
      "  [76 78]]\n",
      "\n",
      " [[80 82]\n",
      "  [88 90]\n",
      "  [96 98]]]\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(a[:, :, np.newaxis].shape)\n",
    "c = (a[:, :, np.newaxis] + b)\n",
    "print(c.shape)\n",
    "d = c[::, ::2, [0, -1]]\n",
    "print(d.shape)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add the two arrays together (remember the rules for broadcasting)\n",
    "* Acess the first and last element of every alternate row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "NumPy arrays are passed by reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b is a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.may_share_memory(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 100   3   4   5]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 100   3   4   5]\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = b.copy() # b[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1] = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 9999,    3,    4,    5])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "a = b[:]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1] = 99999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1, 99999,     3,     4,     5])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1, 99999,     3,     4,     5])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(array):\n",
    "    array *= 2\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = func1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(array):\n",
    "    array = array * 2\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = func2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behaviour is different for integers, floats etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = func1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [a, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3]), array([1, 2, 3])]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loops vs Numpy\n",
    "<br>\n",
    "Let's take a look at how Numpy's built in mathematical functions save us a lot of time by making looping redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 963 µs, sys: 301 µs, total: 1.26 ms\n",
      "Wall time: 705 µs\n",
      "CPU times: user 0 ns, sys: 3.17 ms, total: 3.17 ms\n",
      "Wall time: 3.17 ms\n"
     ]
    }
   ],
   "source": [
    "#core/src/multiarray/ctors.c\n",
    "%time x = np.arange(100000)\n",
    "%time y = list(range(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 283 µs, sys: 89 µs, total: 372 µs\n",
      "Wall time: 250 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4999950000"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 ms, sys: 66 µs, total: 12.5 ms\n",
      "Wall time: 12.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = 0\n",
    "for _ in y:\n",
    "    total += _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 556 µs, sys: 172 µs, total: 728 µs\n",
      "Wall time: 434 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mean = np.average(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.4 ms, sys: 0 ns, total: 30.4 ms\n",
      "Wall time: 29.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "total = 0\n",
    "count = 0\n",
    "for _ in y:\n",
    "    total += _\n",
    "    count += _\n",
    "    \n",
    "total / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which one do you think is faster?\n",
    "<br>\n",
    "abs(3.14159) or np.abs(3.14159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 11.9 µs\n",
      "CPU times: user 24 µs, sys: 1e+03 ns, total: 25 µs\n",
      "Wall time: 28.8 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.14159"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time abs(-3.14159)\n",
    "%time np.abs(-3.14159)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now which one of these do you think is faster? <br>\n",
    "abs([-1, 2, -3, -1, -4] or np.abs([-1, 2, -3, -1, -4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 64 µs, sys: 6 µs, total: 70 µs\n",
      "Wall time: 77 µs\n",
      "CPU times: user 83 µs, sys: 7 µs, total: 90 µs\n",
      "Wall time: 95.1 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2,\n",
       "       3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1,\n",
       "       4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1,\n",
       "       2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3,\n",
       "       1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4,\n",
       "       1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2,\n",
       "       3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1,\n",
       "       4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1,\n",
       "       2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3,\n",
       "       1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4,\n",
       "       1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2,\n",
       "       3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1,\n",
       "       4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1,\n",
       "       2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3,\n",
       "       1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4,\n",
       "       1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2,\n",
       "       3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1,\n",
       "       4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1,\n",
       "       2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3,\n",
       "       1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4,\n",
       "       1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2,\n",
       "       3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1,\n",
       "       4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time [abs(x) for x in [-1, 2, -3, -1, -4] * 100]\n",
    "%time np.abs([-1, 2, -3, -1, -4] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprised? How about this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 139 µs, sys: 8 µs, total: 147 µs\n",
      "Wall time: 153 µs\n",
      "CPU times: user 20 µs, sys: 1 µs, total: 21 µs\n",
      "Wall time: 26.9 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2,\n",
       "       3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1,\n",
       "       4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1,\n",
       "       2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3,\n",
       "       1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4,\n",
       "       1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2,\n",
       "       3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1,\n",
       "       4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1,\n",
       "       2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3,\n",
       "       1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4,\n",
       "       1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2,\n",
       "       3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1,\n",
       "       4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1,\n",
       "       2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3,\n",
       "       1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4,\n",
       "       1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2,\n",
       "       3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1,\n",
       "       4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1,\n",
       "       2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3,\n",
       "       1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4,\n",
       "       1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2,\n",
       "       3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1,\n",
       "       4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array([-1, 2, -3, -1, -4] * 100)\n",
    "%time [abs(x) for x in array]\n",
    "%time np.abs(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stride tricks with numpy. <br><br>\n",
    "Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "s = 2\n",
    "w = 4\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [1, 2, 3, 4],\n",
       "       [2, 3, 4, 5],\n",
       "       [3, 4, 5, 6],\n",
       "       [4, 5, 6, 7],\n",
       "       [5, 6, 7, 8],\n",
       "       [6, 7, 8, 9]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.lib.stride_tricks.as_strided(a, shape = (len(a) - w + 1, w), strides = a.strides * 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [2, 3, 4, 5],\n",
       "       [4, 5, 6, 7],\n",
       "       [6, 7, 8, 9]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.lib.stride_tricks.as_strided(a, shape = (len(a) - w + 1, w), strides = a.strides * 2 )[::s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short aside - <br>\n",
    "`[::]` was added to Python at the request of the developers of Numerical Python, which uses the third argument extensively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]\n",
      " [16 17 18 19]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(20).reshape(5, 4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1],\n",
       "        [ 4,  5]],\n",
       "\n",
       "       [[ 2,  3],\n",
       "        [ 6,  7]],\n",
       "\n",
       "       [[ 4,  5],\n",
       "        [ 8,  9]],\n",
       "\n",
       "       [[ 6,  7],\n",
       "        [10, 11]],\n",
       "\n",
       "       [[ 8,  9],\n",
       "        [12, 13]],\n",
       "\n",
       "       [[10, 11],\n",
       "        [14, 15]],\n",
       "\n",
       "       [[12, 13],\n",
       "        [16, 17]],\n",
       "\n",
       "       [[14, 15],\n",
       "        [18, 19]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.lib.stride_tricks.as_strided(a, shape = (15, 2, 2), strides = (8, 32, 8))[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of striding using [::2], chagne the shape and strides in as_strided to create same effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1],\n",
       "        [ 4,  5]],\n",
       "\n",
       "       [[ 2,  3],\n",
       "        [ 6,  7]],\n",
       "\n",
       "       [[ 4,  5],\n",
       "        [ 8,  9]],\n",
       "\n",
       "       [[ 6,  7],\n",
       "        [10, 11]],\n",
       "\n",
       "       [[ 8,  9],\n",
       "        [12, 13]],\n",
       "\n",
       "       [[10, 11],\n",
       "        [14, 15]],\n",
       "\n",
       "       [[12, 13],\n",
       "        [16, 17]],\n",
       "\n",
       "       [[14, 15],\n",
       "        [18, 19]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.lib.stride_tricks.as_strided(a, shape = (8, 2, 2), strides = (16, 32, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do these arrays look in memory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](NDArray_structure.png \"NDArray Structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': (140641614568528, False),\n",
       " 'descr': [('', '<i8')],\n",
       " 'shape': (10,),\n",
       " 'strides': None,\n",
       " 'typestr': '<i8',\n",
       " 'version': 3}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.__array_interface__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y = np.lib.stride_tricks.as_strided(x, shape = (9, 2), strides = x.strides * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 2],\n",
       "       [2, 3],\n",
       "       [3, 4],\n",
       "       [4, 5],\n",
       "       [5, 6],\n",
       "       [6, 7],\n",
       "       [7, 8],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': (140641614568528, False),\n",
       " 'descr': [('', '<i8')],\n",
       " 'shape': (9, 2),\n",
       " 'strides': (8, 8),\n",
       " 'typestr': '<i8',\n",
       " 'version': 3}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.__array_interface__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Einsum <br>\n",
    "dot, diagonal, trace, sum, matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 1, 1],\n",
    "              [2, 2, 2],\n",
    "              [5, 5, 5]])\n",
    "\n",
    "B = np.array([[0, 1, 0],\n",
    "              [1, 1, 0],\n",
    "              [1, 1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return a view of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  6, 15])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ij -> i', A) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [2, 2, 2],\n",
       "       [5, 5, 5]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Transpose (doesn't work if you want to switch around axes in 3D etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 5],\n",
       "       [1, 2, 5],\n",
       "       [1, 2, 5]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ij -> ji', A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 5],\n",
       "       [1, 2, 5],\n",
       "       [1, 2, 5]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 µs, sys: 1 µs, total: 20 µs\n",
      "Wall time: 26 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.einsum('ii->i', A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 µs, sys: 13 µs, total: 42 µs\n",
      "Wall time: 48.2 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.diag(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49 µs, sys: 7 µs, total: 56 µs\n",
      "Wall time: 66.8 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.einsum('ii -> ', A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum along an axis <br> You try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39 µs, sys: 1 µs, total: 40 µs\n",
      "Wall time: 46.3 µs\n",
      "CPU times: user 53 µs, sys: 0 ns, total: 53 µs\n",
      "Wall time: 59.8 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3,  6, 15])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.einsum('ij->i', A)\n",
    "%time np.sum(A, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Matrix and element-wise multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [2, 2, 0],\n",
       "       [5, 5, 5]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [2, 2, 0],\n",
       "       [5, 5, 5]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ij, ij -> ij', A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  1],\n",
       "       [ 4,  6,  2],\n",
       "       [10, 15,  5]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39 µs, sys: 0 ns, total: 39 µs\n",
      "Wall time: 46 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  1],\n",
       "       [ 4,  6,  2],\n",
       "       [10, 15,  5]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.einsum('ij, jk-> ik', A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 µs, sys: 6 µs, total: 32 µs\n",
      "Wall time: 39.8 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  1],\n",
       "       [ 4,  6,  2],\n",
       "       [10, 15,  5]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.dot(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Einsum and stride tricks to do a convultion operation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](arbitrary_padding_no_strides.gif \"Convolution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](2005-06-26-essence-of-images-convolution-matrix.png \"Convolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.arange(25).reshape((5, 5))\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0]\n",
      " [1 2 3]\n",
      " [0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "conv_filter = np.array([[1, 1, 0], [1, 2, 3], [0, 1, 1]])\n",
    "print(conv_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 3)\n",
      "(40, 8, 40, 8)\n"
     ]
    }
   ],
   "source": [
    "filter_shape = conv_filter.shape\n",
    "conv_shape   = tuple(np.subtract(matrix.shape, filter_shape) + 1) + filter_shape\n",
    "conv_strides = matrix.strides * 2\n",
    "print(conv_shape)\n",
    "print(conv_strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sub_matrices = np.lib.stride_tricks.as_strided(matrix, conv_shape, conv_strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  1  2]\n",
      "   [ 5  6  7]\n",
      "   [10 11 12]]\n",
      "\n",
      "  [[ 1  2  3]\n",
      "   [ 6  7  8]\n",
      "   [11 12 13]]\n",
      "\n",
      "  [[ 2  3  4]\n",
      "   [ 7  8  9]\n",
      "   [12 13 14]]]\n",
      "\n",
      "\n",
      " [[[ 5  6  7]\n",
      "   [10 11 12]\n",
      "   [15 16 17]]\n",
      "\n",
      "  [[ 6  7  8]\n",
      "   [11 12 13]\n",
      "   [16 17 18]]\n",
      "\n",
      "  [[ 7  8  9]\n",
      "   [12 13 14]\n",
      "   [17 18 19]]]\n",
      "\n",
      "\n",
      " [[[10 11 12]\n",
      "   [15 16 17]\n",
      "   [20 21 22]]\n",
      "\n",
      "  [[11 12 13]\n",
      "   [16 17 18]\n",
      "   [21 22 23]]\n",
      "\n",
      "  [[12 13 14]\n",
      "   [17 18 19]\n",
      "   [22 23 24]]]]\n"
     ]
    }
   ],
   "source": [
    "print(sub_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "convolved = np.einsum('ij, ijkl->kl', conv_filter, sub_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 62  72  82]\n",
      " [112 122 132]\n",
      " [162 172 182]]\n"
     ]
    }
   ],
   "source": [
    "print(convolved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a = np.arange(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Window this array such that each window has 3 elements in it with a jump of 2 windows\n",
    "* Find the row-wise mean of the last two elements in every alternate row.\n",
    "\n",
    "(Answer - [7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ProbabilityDensityFunction(np.lib.mixins.NDArrayOperatorsMixin):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self._pdf_              = kwargs.get('probabilities', np.tile(0.5, kwargs.get('shape', (2, 2))))\n",
    "        self._HANDLED_TYPES_    = (np.ndarray, type(self))\n",
    "        if not np.allclose(self._pdf_.sum(), 1.0):\n",
    "            self._pdf_ /= self._pdf_.sum()\n",
    "            self._pdf_  = np.nan_to_num(self._pdf_)\n",
    "\n",
    "    def __array_ufunc__(self, ufunc, method, *inputs, **kwargs):\n",
    "        out = kwargs.get('out', ())\n",
    "        for x in inputs + out:\n",
    "            if not isinstance(x, self._HANDLED_TYPES_):\n",
    "                return NotImplemented\n",
    "        inputs = tuple(x._pdf_ if isinstance(x, ProbabilityDensityFunction) else x for x in inputs)\n",
    "        if out:\n",
    "            kwargs['out'] = (x._pdf_ if isinstance(x, ProbabilityDensityFunction) else x for x in out)\n",
    "        result = getattr(ufunc, method)(*inputs, **kwargs)\n",
    "\n",
    "        if type(result) is tuple:\n",
    "            return tuple(type(self)(probabilities = x) for x in result)\n",
    "        elif method == 'at':\n",
    "            return None\n",
    "        else:\n",
    "            return type(self)(probabilities = result)\n",
    "\n",
    "    def __call__(self, **kwargs):\n",
    "        return self._pdf_\n",
    "\n",
    "    def __repr__(self):\n",
    "        '''  '''\n",
    "        repr_string = 'PDF: \\n%s' % (\n",
    "            self._pdf_.__str__()\n",
    "        )\n",
    "        return repr_string\n",
    "    \n",
    "pdf = ProbabilityDensityFunction()\n",
    "print(np.subtract(pdf, pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0; a = 10  # x center, half width                                       \n",
    "y0 = 0; b = 3  # y center, half height\n",
    "\n",
    "x = np.linspace(-12, 12, 24)  # x values of interest\n",
    "y = np.linspace(-12, 12, 24)[:, np.newaxis]  # y values of interest, as a \"column\" array\n",
    "\n",
    "ellipse = ((x - x0) / a) ** 2 + ((y - y0) / b) ** 2 <= 1  # True for points inside the ellipse\n",
    "\n",
    "print(ellipse.astype(np.int))\n",
    "\n",
    "x = np.linspace(-12, 12, 24)  # x values of interest\n",
    "y = np.linspace(-12, 12, 24)[:, np.newaxis]  # y values of interest, as a \"column\" array\n",
    "circle = x ** 2 + y ** 2 <= 16  # True for points inside the circle\n",
    "\n",
    "rint(circle.astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy’s memmap’s are array-like objects. This differs from Python’s mmap module, which uses file-like objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = path.join(mkdtemp(), 'bigfile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = np.memmap(filename, dtype='float32', mode='w+', shape=(1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = np.memmap(filename, dtype='float32', mode='readwrite', shape=(1000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quick example: gene expression, without numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Gene   | Cell type A | Cell type B | Cell type C | Cell type D |\n",
    "|--------|-------------|-------------|-------------|-------------|\n",
    "| Gene 0 | 100         | 200         | 50          | 400         |\n",
    "| Gene 1 | 50          | 0           | 0           | 100         |\n",
    "| Gene 2 | 350         | 100         | 50          | 200         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene0 = [100, 200, 50, 400]\n",
    "gene1 = [50, 0, 0, 100]\n",
    "gene2 = [350, 100, 50, 200]\n",
    "expression_data = [gene0, gene1, gene2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this a bad idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array(expression_data)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to:\n",
    "\n",
    "* Obtain an *RPKM* expression matrix\n",
    "* Quantile normalize the data\n",
    "\n",
    "using the awesome power of NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inside a numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(a):\n",
    "    print('number of elements:', a.size)\n",
    "    print('number of dimensions:', a.ndim)\n",
    "    print('shape:', a.shape)\n",
    "    print('data type:', a.dtype)\n",
    "    print('strides:', a.strides)\n",
    "    print('flags:')\n",
    "    print(a.flags)\n",
    "    \n",
    "print_info(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abytes = a.ravel().view(dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(abytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abytes[:24])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: take the transpose of `a`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(a.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: skipping rows and columns with *slicing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(a.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(a.T[::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(a.T[::2, ::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0, 0] = 5\n",
    "print(b)\n",
    "a[0, 0] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced operations: axis-wise evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = np.load('expr.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has the raw read count data. However, each sample gets a different number of reads, so we want to normalize by the *library size*, which is the total number of reads across a column.\n",
    "\n",
    "The `np.sum` function returns the sum of all the elements of an array. With the `axis` argument, you can take the sum *along the given axis*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_size = np.sum(expr, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Generate a 10 x 3 array of random numbers. From each row, pick the column containing the number closest to 0.75.\n",
    "\n",
    "*Hint:* use of `np.abs` and `np.argmin` to find the column j that contains the closest element in each row i. The final result should be a vector of integers of shape (10,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.random((10, 3))\n",
    "\n",
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Some applications, such as clustering, are computationally expensive, and wouldn't work without first doing some form of *feature selection*, where we discard most of the data and keep only what we think will be most useful. One simple version is to keep only the genes with the most variance (as these will be more informative than genes that don't vary between patients).\n",
    "\n",
    "- Find the variance across patients of all the genes (rows) in the expression dataset.\n",
    "- Use `np.argsort` to find the location of the 1,500 most variable genes.\n",
    "- Use these indices to produce a shape (1500, 375) matrix containing only the most variable genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced operations: broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to normalize every column by its corresponding library size, we have to *align* the two arrays' axes: each dimension must be either the same size, or one of the arrays must have size 1. Use `np.newaxis` to match the dimensions. But let's first do some simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + 5  # simplest \"broadcasting\": scalar - array operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1, 2, 3, 4])\n",
    "a + b  # broadcasting: coerce arrays to same shape by repeating as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1, 2, 3])\n",
    "a + b  # broadcasting: not just magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1], [2], [3]])\n",
    "a + b  # broadcasting: shape compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, back to our expression data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expr.shape)\n",
    "print(lib_size.shape)\n",
    "print(lib_size[np.newaxis, :].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, NumPy will automatically prepend singleton dimensions until the array shapes match or there is an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(expr / lib_size ==\n",
    "       expr / lib_size[np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_lib = expr / lib_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also multiply by $10^6$ in order to keep the numbers on a readable scale (reads per million reads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_lib *= 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, longer genes are more likely to produce reads. So we must normalize by the gene length (in kb) to produce a measure of expression called Reads Per Kilobase per Million reads (RPKM). We start by loading the gene lengths in *bases*. (1 kilobase = 1,000 bases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_len = np.load('gene-lens.npy')\n",
    "print(gene_len.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: broadcast `expr_lib` and `gene_len` together to produce RPKM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder:\n",
    "\n",
    "$RPKM = \\frac{C}{N \\times 10^{-6} \\times L \\times 10^{-3}} = \\frac{10^9C}{NL}$\n",
    "\n",
    "where $C$ is the raw counts, $N$ is the library size (in reads) and $L$ is the gene length (in bases). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpkm = ...  # FIX THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to admire our handywork, we will use a custom plotting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "def plot_col_density(data, xlim=None, *args, **kwargs):\n",
    "    # Use gaussian smoothing to estimate the density\n",
    "    density_per_col = [stats.kde.gaussian_kde(col) for col in data.T]\n",
    "    if xlim is not None:\n",
    "        m, M = xlim\n",
    "    else:\n",
    "        m, M = np.min(data), np.max(data)\n",
    "    x = np.linspace(m, M, 100)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for density in density_per_col:\n",
    "        ax.plot(x, density(x), *args, **kwargs)\n",
    "    ax.set_xlabel('log-counts')\n",
    "    ax.set_ylabel('frequency')\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_col_density(np.log(expr+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_col_density(np.log(rpkm + 1), xlim=(0, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the most \"disparate\" data column is now a much better fit with the rest of the data. This should improve downstream scientific analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: 3D broadcasting\n",
    "\n",
    "Below, using broadcasting, produce the array containing the sum of every element in `x` with every element in `y`. That is, produce an array `z` such that `z[i, j, k]` contains either the sum of `x[i]` and `y[j, k]` OR the sum of `y[i, j]` and `x[k]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random(size=(3, 5))\n",
    "y = np.random.randint(10, size=8)\n",
    "z = x # FIX THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: explicit broadcasting and stride tricks\n",
    "\n",
    "Now, use `np.broadcast_arrays` to `xbroad` and `ybroad` that are the same shape as `z` (so that a simple element-wise addition will give `z`). Then use `print_info` on `xbroad` and `ybroad`. Notice anything weird?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride tricks\n",
    "\n",
    "By manipulating the shape and strides of an array, we can produce a \"virtual\" array much bigger than its memory usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat(arr, n):\n",
    "    return np.lib.stride_tricks.as_strided(arr,\n",
    "                                           shape=(n,) + arr.shape,\n",
    "                                           strides=(0,) + arr.strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_row = repeat(np.random.random(size=5), 4)\n",
    "repeated_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful, though: some operations, such as `np.copy`, actually materialize the much bigger array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(repeated_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(np.copy(repeated_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((3, 2)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to answer these without looking at `x`. Then, try them out with the `print_info` function.\n",
    "\n",
    "- What is the shape of `x`?\n",
    "- What are the strides of `x`?\n",
    "- Is `x` C-contiguous, F-contiguous, or neither?\n",
    "\n",
    "Now let `y = repeat(x, 4)`. What is its shape? What are its strides? Is it contiguous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: `np.lib.stride_tricks.as_strided`\n",
    "\n",
    "Use `as_strided` to produce a sliding-window view of a 1D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(arr, size=2):\n",
    "    \"\"\"Produce an array of sliding window views of `arr`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : 1D array, shape (N,)\n",
    "        The input array.\n",
    "    size : int, optional\n",
    "        The size of the sliding window.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    arr_slide : 2D array, shape (N - size + 1, size)\n",
    "        The sliding windows of size `size` of `arr`.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> a = np.array([0, 1, 2, 3])\n",
    "    >>> sliding_window(a, 2)\n",
    "    array([[0, 1],\n",
    "           [1, 2],\n",
    "           [2, 3]])\n",
    "    \"\"\"\n",
    "    return arr  # fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your code here\n",
    "sliding_window(np.arange(8), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: mean filtering\n",
    "\n",
    "Use `sliding_window` to implement mean filtering, in which every value in an array is replaced by the mean of it and its neighbours. This is a basic operation in signal processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_filter(signal, window_size=3):\n",
    "    \"\"\"Apply a mean filter to the input with the desired window size.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : 1D array, shape (M,)\n",
    "        The input signal.\n",
    "    window_size : int, optional\n",
    "        The size of the window along which to compute the mean.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    filtered : 1D array, shape (M - window_size + 1,)\n",
    "        The filtered signal.\n",
    "    \"\"\"\n",
    "    return signal  # FIX THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your function, we will use the example of a *difference filter*, which finds the location of changes in a signal using *convolution*. When the signal is perfectly noiseless, it works great:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = np.zeros(100, np.float)\n",
    "signal[30:60] = 1\n",
    "\n",
    "diff = np.array([1, 0, -1])\n",
    "from scipy import ndimage as ndi\n",
    "dsignal = ndi.convolve(signal, diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot(signal)\n",
    "ax[0].set_title('signal')\n",
    "ax[1].plot(dsignal)\n",
    "ax[1].set_title('change')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if the signal is corrupted by noise, a standard difference filter convolution doesn't work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "signal_noisy = signal + np.random.normal(0, 0.3, size=signal.shape)\n",
    "dsignal_noisy = ndi.convolve(signal_noisy, diff)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot(signal_noisy)\n",
    "ax[0].set_title('signal')\n",
    "ax[1].plot(dsignal_noisy)\n",
    "ax[1].set_title('change')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try mean filtering with different window sizes to see whether the change signal becomes more apparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: padding\n",
    "\n",
    "What is the shape of your mean-filtered signal?\n",
    "\n",
    "...\n",
    "\n",
    "Oops! We've shortened the signal, which means that our indices have changed: `signal_filtered[i]` does not correspond to the signal around `signal[i]`.\n",
    "\n",
    "Use `np.pad` to add some \"fake\" data around `signal` before filtering, so that the filtered result has the same shape as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Gaussian filtering\n",
    "\n",
    "It turns out that mean filtering is not the \"optimal\" way to recover your signal, assuming certain properties of the noise. For that, we use *Gaussian* filtering, which uses a *weighted* mean of the sliding window elements. The weights are given by the famous Gaussian bell-shaped distribution. For example, here are the weights for a window size of 17 for a particular sigma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = np.exp(-(np.arange(-8, 9) / (8/3))**2)\n",
    "weight /= np.sum(weight)  ## ensure overall intensity of signal doesn't change\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that uses sliding windows, broadcasting, and axis-wise operations to compute the Gaussian filter of a signal for a given window size. (You should also pad your input.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fancy indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can index arrays with slicing, but also with boolean arrays (including broadcasting!), integer arrays, and individual indices along multiple dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([0, 5, 99])\n",
    "selector = np.random.randint(0, 3, size=(3, 4))\n",
    "print(selector)\n",
    "print(values[selector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relabeled = values[selector]\n",
    "has_large_cols = np.any(relabeled > 10, axis=1)\n",
    "print(relabeled[has_large_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use boolean indexing and broadcasting to select the columns of `relabeled` that do not contain 99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: quantile normalization\n",
    "\n",
    "Quantile Normalization (https://en.wikipedia.org/wiki/Quantile_normalization) is a method to align distributions. Here we implement it using NumPy axis-wise operations and fancy indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qnorm(X):\n",
    "    \"\"\"Quantile normalize an input matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2D array of float, shape (M, N)\n",
    "        The input data, with each column being a\n",
    "        distribution to normalize.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Xn : 2D array of float, shape (M, N)\n",
    "        The normalized data.\n",
    "    \"\"\"\n",
    "    ranks = \n",
    "    return Xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logexpr = np.log(expr + 1)\n",
    "logrpkm = np.log(rpkm + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logexprn = qnorm(logexpr)\n",
    "logrpkmn = qnorm(logrpkm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_col_density(logexprn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_col_density(logrpkmn, xlim=(0, 0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fancy indexing along multiple dimensions\n",
    "\n",
    "Combining fancy indexing and slicing selects entire rows/columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relabeled[[1, 1, 2], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relabeled[:, [1, 3, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select individual elements for a new array shape, we must use as many fancy indices as the array has dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_rows = [[0, 0],\n",
    "                 [1, 2]]\n",
    "selector_cols = [[0, 3],\n",
    "                 [1, 2]]\n",
    "\n",
    "arr = np.arange(12).reshape((3, 4))\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr[selector_rows, selector_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to think about this is:\n",
    "- make a \"coordinate array\", of the shape that you want plus one more axis, to hold the coordinates of each point (see below),\n",
    "- transpose that final axis to the front, and\n",
    "- convert to tuple\n",
    "\n",
    "For the above example, perhaps you find this \"notation\", with the individual coordinates in the final axis, more intuitive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_t = [[ [0, 0], [0, 3] ],\n",
    "              [ [1, 1], [2, 2] ]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, we want element (0, 0) in the top left corner, (0, 3) in the top right, (1, 1) in the bottom left, and (2, 3) in the bottom right. However, *rows and columns* must be in the first dimension and presented as a tuple to index the original array. So, to use this notation, we can use np.transpose and cast the result to `tuple`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = tuple(np.transpose(selector_t, (2, 0, 1)))\n",
    "print(selector[0], selector[1], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For technical reasons that one might grasp for fleeting moments, the \"tuple of index arrays\" format is most consistent with other forms of multi-dimensional indexing in NumPy. It is a widespread convention (see e.g. `scipy.ndimage.map_coordinates`), so it's worth practicing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "What happens when you make `selector_col`:\n",
    "- a single number?\n",
    "- a 1D array with two elements?\n",
    "- a 2D array of shape (1, 2)?\n",
    "- a 1D array with three elements?\n",
    "\n",
    "Repeat similar experiments with `selector_row`.\n",
    "\n",
    "Does this remind you of any other NumPy feature we may have seen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced exercise: Jack's dilemma\n",
    "\n",
    "(If time permits.)\n",
    "\n",
    "```email\n",
    "Date: Wed, 16 Jul 2008 16:45:37 -0500\n",
    "From: Jack Cook\n",
    "To: <numpy-discussion@scipy.org>\n",
    "Subject: Numpy Advanced Indexing Question\n",
    "```\n",
    "\n",
    "Greetings,\n",
    "\n",
    "I have an I,J,K 3D volume of amplitude values at regularly sampled\n",
    "time intervals. I have an I,J 2D slice which contains a time (K)\n",
    "value at each I, J location. What I would like to do is extract a\n",
    "subvolume at a constant +/- K window around the slice. Is there an\n",
    "easy way to do this using advanced indexing or some other method?\n",
    "Thanks in advanced for your help.\n",
    "\n",
    "-- Jack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the command-line, run `python tools/generate-volume.py`\n",
    "\n",
    "data = np.load('geo.npz')  # npz file with multiple arrays, keyed like dict\n",
    "strata, density = data['strata'], data['density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 256\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, sharey=True, figsize=(7.2, 3.6))\n",
    "ax0.imshow(strata[:, row, :], cmap='gray')\n",
    "ax0.set_ylabel('depth')\n",
    "ax0.set_xlabel('x')\n",
    "ax0.set_title(f'strata at row {row}')\n",
    "ax1.imshow(density[:, 256, :], cmap='magma')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_title(f'fossil density at row {row}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "We want to quantify the apparent extinction event near a particular stratum. The strata, however, are not perfectly horizontal, and there is a large break in the rock, too. Therefore, we want to align the strata by using the solution to Jack's dilemma (which you must solve for him).\n",
    "\n",
    "Using a window size of 120 (so the half-width is K=60):\n",
    "- find the stratum of maximum intensity along the depth axis. This is a 2D slice of integers measuring the depth of the maximum intensity stratum at each (row, column) coordinate.\n",
    "- using broadcasting, create a volume of shape (2K, Nrow, Ncol) containing the depth coordinate at each (row, column) of your desired window.\n",
    "- create matching row and column index volumes to perform fancy indexing of the fossil density array.\n",
    "- extract the subvolume of fossil density around the stratum using fancy indexing\n",
    "- compute the mean fossil density at each depth.\n",
    "\n",
    "**-->Advice<--**: play around with a much tinier subset of the volume, say, a subset of size (10, 15, 20), and window size of 3. Evaluating the wrong expression can result in a giant dataset that blows up your memory and crashes your computer. (Yay Science!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear algebra with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since version 3.5, Python supports the matrix multiplication operator, denoted by the `@` symbol. This makes it a new powerhouse for linear algebra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[0, 1],\n",
    "              [1, 1],\n",
    "              [1, 0]])\n",
    "v = np.array([9, 2])\n",
    "\n",
    "print(M @ v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M.T @ M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider the rotation matrix\n",
    "\n",
    "$\n",
    "R = \\begin{bmatrix}\n",
    "  \\cos \\theta &  -\\sin \\theta & 0 \\\\\n",
    "  \\sin \\theta & \\cos \\theta & 0\\\\\n",
    "  0 & 0 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "When $R$ is multiplied with a 3-dimensional column-vector $p =\n",
    "\\left[ x\\, y\\, z \\right]^T$, the resulting vector $R p$ is rotated\n",
    "by $\\theta$ degrees around the z-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_deg = 45\n",
    "theta = np.deg2rad(theta_deg)\n",
    "\n",
    "c = np.cos(theta)\n",
    "s = np.sin(theta)\n",
    "\n",
    "R = np.array([[c, -s, 0],\n",
    "              [s,  c, 0],\n",
    "              [0,  0, 1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.array([1, 0, 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R @ x_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = R @ x_axis\n",
    "R @ rotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: rotation matrices\n",
    "\n",
    "If you know some linear algebra, try to answer the following questions about $R$ in your head, before trying them out in Python. If you're totally stuck, just give them a go!\n",
    "\n",
    "- What does the matrix $S = RR$ do? (Remember, `S = R @ R` in code.)\n",
    "- What does $R^4 = RRRR$ do?\n",
    "- The inverse $R^{-1}$ of $R$ is defined as the matrix such that $R^{-1}R = I$, where $I$ is the identity matrix. What does $Q = R^{-1}$ do? (Note: NumPy provides matrix inverse computation in `np.linalg.inv`.)\n",
    "- What does $R$ do to the vector [0, 0, 1]?\n",
    "- What does that make the vector [0, 0, 1]?\n",
    "- Verify this with some function in `np.linalg`. (Look at the online documentation for this module.)\n",
    "- What does $R^8$ do? What does that make $R^8$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: revisiting Gaussian filtering\n",
    "\n",
    "Above, we performed Gaussian filtering with a broadcast product and a axis-wise sum. Use a matrix multiplication instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random(size=(n, 3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a vector y of length n that is 0 at position i if `X[i, 0] + X[i, 2] < 1`, and 1 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint:* How do I get the 0th column of X?\n",
    "\n",
    "*Hint 2:* How can I convert an array of (True/False) to an array of float?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (X[:, 0] + X[:, 2] > 1).astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 2], X[:, 0], color=plt.cm.viridis(y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb = np.column_stack((X, np.ones(X.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 2 * np.random.random(size=Xb.shape[1]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = sigmoid(Xb @ W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsigmoid(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, W, n_iter=100):\n",
    "    W_history = np.empty((n_iter, W.size), dtype=float)\n",
    "    error_history = np.empty(n_iter, dtype=float)\n",
    "    W_out = np.copy(W)\n",
    "    for i in range(n_iter):\n",
    "        W_history[i] = W_out\n",
    "        predictions = sigmoid(X @ W_out)\n",
    "        derror = y - predictions\n",
    "        gradient = derror * dsigmoid(predictions)  # iamtrask\n",
    "        update = X.T @ gradient\n",
    "        error_history[i] = np.sum(np.abs(error))\n",
    "        W_out += update\n",
    "    return W_out, W_history, error_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wout, Whist, errhist = train(Xb, y, W, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(errhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mgrid[0:1:0.3, 0:1:0.3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_space = np.mgrid[0:1:0.01, 0:1:1, 0:1:0.01, 1:2:1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_image = sigmoid(decision_space.T @ Wout).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_squeezed = np.squeeze(prediction_image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(prediction_squeezed, cmap='magma', origin='lower',\n",
    "          extent=[0, 1, 0, 1])\n",
    "ax.scatter(X[:, 2], X[:, 0], color=plt.cm.viridis(y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Why do some points appear misclassified?\n",
    "\n",
    "*Hint:* Look at `Wout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and sources\n",
    "\n",
    "In addition to original content, these notes use materials from the following sources:\n",
    "\n",
    "- [100 NumPy Exercises](http://www.labri.fr/perso/nrougier/teaching/numpy.100/), compiled by Nicolas Rougier, used here under the terms of the MIT License.\n",
    "- [SciPy Lecture Notes](http://www.scipy-lectures.org/), compiled by Gaël Varoquaux, Emmanuelle Gouillart, and Olav Vahtras, used under the terms of the CC-BY license.\n",
    "- [Elegant SciPy](http://elegant-scipy.org), written by Juan Nunez-Iglesias, Stéfan van der Walt, and Harriet Dashnow, used with permission from O'Reilly.\n",
    "- [iamtrask blog](https://iamtrask.github.io/2015/07/12/basic-python-network/), for a neural network from scratch that inspired this one.\n",
    "- https://github.com/brandon-rhodes/pycon-pandas-tutorial\n",
    "- https://github.com/geo-python/2018/tree/master/source/lessons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas = Python+Numpy+R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical analytical steps-\n",
    "1. Load data into dataframe\n",
    "2. Reformat columns and add row indices\n",
    "3. Select subset of rows \n",
    "4. Aggregate and Subtotal with GroupBy\n",
    "5. Post Process for Display\n",
    "6. Compare with other Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two data files are not included in the repo, you can download them from: [`titles.csv`](https://drive.google.com/file/d/0B3G70MlBnCgKa0U4WFdWdGdVOFU/view?usp=sharing) and [`cast.csv`](https://drive.google.com/file/d/0B3G70MlBnCgKRzRmTWdQTUdjNnM/view?usp=sharing) and put them in the `/data` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoPandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to geospatial vector data in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing geospatial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geospatial data is often available from specific GIS file formats or data stores, like ESRI shapefiles, GeoJSON files, geopackage files, PostGIS (PostgreSQL) database, ...\n",
    "\n",
    "We can use the GeoPandas library to read many of those GIS file formats (relying on the `fiona` library under the hood, which is an interface to GDAL/OGR), using the `geopandas.read_file` function.\n",
    "\n",
    "For example, let's start by reading a shapefile with all the countries of the world (adapted from http://www.naturalearthdata.com/downloads/110m-cultural-vectors/110m-admin-0-countries/, zip file is available in the `/data` directory), and inspect the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = geopandas.read_file(\"zip://./data/ne_110m_admin_0_countries.zip\")\n",
    "# or if the archive is unpacked:\n",
    "# countries = geopandas.read_file(\"data/ne_110m_admin_0_countries/ne_110m_admin_0_countries.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we observe:\n",
    "\n",
    "- Using `.head()` we can see the first rows of the dataset, just like we can do with Pandas.\n",
    "- There is a 'geometry' column and the different countries are represented as polygons\n",
    "- We can use the `.plot()` method to quickly get a *basic* visualization of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's a GeoDataFrame?\n",
    "\n",
    "We used the GeoPandas library to read in the geospatial data, and this returned us a `GeoDataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GeoDataFrame contains a tabular, geospatial dataset:\n",
    "\n",
    "* It has a **'geometry' column** that holds the geometry information (or features in GeoJSON).\n",
    "* The other columns are the **attributes** (or properties in GeoJSON) that describe each of the geometries\n",
    "\n",
    "Such a `GeoDataFrame` is just like a pandas `DataFrame`, but with some additional functionality for working with geospatial data:\n",
    "\n",
    "* A `.geometry` attribute that always returns the column with the geometry information (returning a GeoSeries). The column name itself does not necessarily need to be 'geometry', but it will always be accessible as the `.geometry` attribute.\n",
    "* It has some extra methods for working with spatial data (area, distance, buffer, intersection, ...), which we will see in later notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(countries.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.geometry.area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's still a DataFrame**, so we have all the pandas functionality available to use on the geospatial dataset, and to do data manipulations with the attributes and geometry information together.\n",
    "\n",
    "For example, we can calculate average population number over all countries (by accessing the 'pop_est' column, and calling the `mean` method on it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries['pop_est'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can use boolean filtering to select a subset of the dataframe based on a condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa = countries[countries['continent'] == 'Africa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The rest of the tutorial is going to assume you already know some pandas basics, but we will try to give hints for that part for those that are not familiar.   \n",
    "A few resources in case you want to learn more about pandas:\n",
    "\n",
    "- Pandas docs: https://pandas.pydata.org/pandas-docs/stable/10min.html\n",
    "- Other tutorials: chapter from pandas in https://jakevdp.github.io/PythonDataScienceHandbook/, https://github.com/jorisvandenbossche/pandas-tutorial, https://github.com/TomAugspurger/pandas-head-to-tail, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"font-size:120%\">\n",
    "\n",
    "**REMEMBER:** <br>\n",
    "\n",
    "* A `GeoDataFrame` allows to perform typical tabular data analysis together with spatial operations\n",
    "* A `GeoDataFrame` (or *Feature Collection*) consists of:\n",
    "    * **Geometries** or **features**: the spatial objects\n",
    "    * **Attributes** or **properties**: columns with information about each spatial object\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometries: Points, Linestrings and Polygons\n",
    "\n",
    "Spatial **vector** data can consist of different types, and the 3 fundamental types are:\n",
    "\n",
    "![](img/simple_features_3_text.svg)\n",
    "\n",
    "* **Point** data: represents a single point in space.\n",
    "* **Line** data (\"LineString\"): represents a sequence of points that form a line.\n",
    "* **Polygon** data: represents a filled area.\n",
    "\n",
    "And each of them can also be combined in multi-part geometries (See https://shapely.readthedocs.io/en/stable/manual.html#geometric-objects for extensive overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example we have seen up to now, the individual geometry objects are Polygons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(countries.geometry[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import some other datasets with different types of geometry objects.\n",
    "\n",
    "A dateset about cities in the world (adapted from http://www.naturalearthdata.com/downloads/110m-cultural-vectors/110m-populated-places/, zip file is available in the `/data` directory), consisting of Point data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = geopandas.read_file(\"zip://./data/ne_110m_populated_places.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cities.geometry[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a dataset of rivers in the world (from http://www.naturalearthdata.com/downloads/50m-physical-vectors/50m-rivers-lake-centerlines/, zip file is available in the `/data` directory) where each river is a (multi-)line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers = geopandas.read_file(\"zip://./data/ne_50m_rivers_lake_centerlines.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rivers.geometry[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `shapely` library\n",
    "\n",
    "The individual geometry objects are provided by the [`shapely`](https://shapely.readthedocs.io/en/stable/) library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(countries.geometry[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct one ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon, LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Point(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = Polygon([(1, 1), (2,2), (2, 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"font-size:120%\">\n",
    "\n",
    "**REMEMBER**: <br><br>\n",
    "\n",
    "Single geometries are represented by `shapely` objects:\n",
    "\n",
    "* If you access a single geometry of a GeoDataFrame, you get a shapely geometry object\n",
    "* Those objects have similar functionality as geopandas objects (GeoDataFrame/GeoSeries). For example:\n",
    "    * `single_shapely_object.distance(other_point)` -> distance between two points\n",
    "\n",
    "    * `geodataframe.distance(other_point)` ->  distance for each point in the geodataframe to the other point\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting our different layers together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = countries.plot(edgecolor='k', facecolor='none', figsize=(15, 10))\n",
    "rivers.plot(ax=ax)\n",
    "cities.plot(ax=ax, color='red')\n",
    "ax.set(xlim=(-20, 60), ylim=(-40, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [04-more-on-visualization.ipynb](04-more-on-visualization.ipynb) notebook for more details on visualizing geospatial datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's practice!\n",
    "\n",
    "For the exercises, we are going to use some data of the city of Paris:\n",
    "\n",
    "- The administrative districts of Paris (https://opendata.paris.fr/explore/dataset/quartier_paris/): `paris_districts_utm.geojson`\n",
    "- Real-time (at the moment I downloaded them ..) information about the public bicycle sharing system in Paris (vélib, https://opendata.paris.fr/explore/dataset/stations-velib-disponibilites-en-temps-reel/information/): `paris_sharing_bike_stations_utm.geojson`\n",
    "\n",
    "Both datasets are provided as GeoJSON files.\n",
    "\n",
    "Let's explore those datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>EXERCISE</b>:\n",
    "\n",
    "* Read both datasets into a GeoDataFrame called `districts` and `stations`.</li>\n",
    "* Check the type of the returned objects (with `type(..)`)</li>\n",
    "* Check the first rows of both dataframes. What kind of geometries do those datasets contain?</li> \n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/01-introduction-geospatial-data1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/01-introduction-geospatial-data2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/01-introduction-geospatial-data3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/01-introduction-geospatial-data4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>EXERCISE</b>:\n",
    "\n",
    "* Make a plot of the `districts` dataset.\n",
    "* Set the figure size to (12, 6) (hint: the `plot` method accepts a figsize keyword).\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/01-introduction-geospatial-data5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>EXERCISE</b>:\n",
    "\n",
    "* Make a plot of the `stations` dataset (also with a (12, 6) figsize).\n",
    "* Use the `'available_bikes'` colums to determine the color of the points. For this, use the `column=` keyword.\n",
    "* Use the `legend=True` keyword to show a color bar.\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/01-introduction-geospatial-data6.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>EXERCISE</b>:\n",
    " <ul>\n",
    "  <li>Visualize the `stations` and `districts` datasets together on a single plot (of 20, 10)).</li>\n",
    "  <li>Use a grey color for the `districts` dataset with an alpha of 0.5, but use black lines (tip: `edgecolor`).</li>\n",
    "  <li>You can use `ax.set_axis_off()` to remove the axis (tick)labels.</li>\n",
    " </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/01-introduction-geospatial-data7.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>EXERCISE</b>:\n",
    "  <p>\n",
    " <ul>\n",
    "  <li>What is the largest district? (the biggest area)</li>\n",
    " </ul> \n",
    "  </p>\n",
    " <details><summary>Hint</summary>You can find the location of the largest value with `.idxmax()`</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/01-introduction-geospatial-data8.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/01-introduction-geospatial-data9.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>EXERCISE</b>:\n",
    "\n",
    " <ul>\n",
    "  <li>Make a histogram showing the distribution of the number of bike stands in the stations.</li>\n",
    " </ul> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/01-introduction-geospatial-data10.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>EXERCISE</b>:\n",
    "\n",
    "* Add a column `'population_density'` representing the number of inhabitants per squared kilometer (Note: The area is given in squared meter, so you will need to multiply the result with `10**6`).\n",
    "* Plot the districts using the `'population_density'` to color the polygons.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/01-introduction-geospatial-data11.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/01-introduction-geospatial-data12.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate reference systems\n",
    "\n",
    "A **coordinate reference system (CRS)** determines how the two-dimensional (planar) coordinates of the geometry objects should be related to actual places on the (non-planar) earth.\n",
    "\n",
    "For a nice in-depth explanation, see https://docs.qgis.org/2.8/en/docs/gentle_gis_introduction/coordinate_reference_systems.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GeoDataFrame or GeoSeries has a `.crs` attribute which holds (optionally) a description of the coordinate reference system of the geometries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `countries` dataframe, it indicates that it used the EPSG 4326 / WGS84 lon/lat reference system, which is one of the most used.  \n",
    "It uses coordinates as latitude and longitude in degrees, as can you be seen from the x/y labels on the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.crs` attribute is given as a dictionary. In this case, it only indicates the EPSG code, but it can also contain the full \"proj4\" string (in dictionary form). \n",
    "\n",
    "Under the hood, GeoPandas uses the `pyproj` / `proj4` libraries to deal with the re-projections.\n",
    "\n",
    "For more information, see also http://geopandas.readthedocs.io/en/latest/projections.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "There are sometimes good reasons you want to change the coordinate references system of your dataset, for example:\n",
    "\n",
    "- different sources with different crs -> need to convert to the same crs\n",
    "- distance-based operations -> if you a crs that has meter units (not degrees)\n",
    "- plotting in a certain crs (eg to preserve area)\n",
    "\n",
    "We can convert a GeoDataFrame to another reference system using the `to_crs` function. \n",
    "\n",
    "For example, let's convert the countries to the World Mercator projection (http://epsg.io/3395):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Antartica, as the Mercator projection cannot deal with the poles\n",
    "countries = countries[(countries['name'] != \"Antarctica\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_mercator = countries.to_crs(epsg=3395)  # or .to_crs({'init': 'epsg:3395'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_mercator.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the different scale of x and y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit more on importing and creating GeoDataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on `fiona`\n",
    "\n",
    "Under the hood, GeoPandas uses the [Fiona library](http://toblerity.org/fiona/) (pythonic interface to GDAL/OGR) to read and write data. GeoPandas provides a more user-friendly wrapper, which is sufficient for most use cases. But sometimes you want more control, and in that case, to read a file with fiona you can do the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from shapely.geometry import shape\n",
    "\n",
    "with fiona.Env():\n",
    "    with fiona.open(\"zip://./data/ne_110m_admin_0_countries.zip\") as collection:\n",
    "        for feature in collection:\n",
    "            # ... do something with geometry\n",
    "            geom = shape(feature['geometry'])\n",
    "            # ... do something with properties\n",
    "            print(feature['properties']['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a GeoDataFrame manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopandas.GeoDataFrame({\n",
    "    'geometry': [Point(1, 1), Point(2, 2)],\n",
    "    'attribute1': [1, 2],\n",
    "    'attribute2': [0.1, 0.2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a GeoDataFrame from an existing dataframe\n",
    "\n",
    "For example, if you have lat/lon coordinates in two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {'City': ['Buenos Aires', 'Brasilia', 'Santiago', 'Bogota', 'Caracas'],\n",
    "     'Country': ['Argentina', 'Brazil', 'Chile', 'Colombia', 'Venezuela'],\n",
    "     'Latitude': [-34.58, -15.78, -33.45, 4.60, 10.48],\n",
    "     'Longitude': [-58.66, -47.91, -70.66, -74.08, -66.86]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Coordinates']  = list(zip(df.Longitude, df.Latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Coordinates'] = df['Coordinates'].apply(Point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.GeoDataFrame(df, geometry='Coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See http://geopandas.readthedocs.io/en/latest/gallery/create_geopandas_from_pandas.html#sphx-glr-gallery-create-geopandas-from-pandas-py for full example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial relationships and operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = geopandas.read_file(\"zip://./data/ne_110m_admin_0_countries.zip\")\n",
    "cities = geopandas.read_file(\"zip://./data/ne_110m_populated_places.zip\")\n",
    "rivers = geopandas.read_file(\"zip://./data/ne_50m_rivers_lake_centerlines.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial relationships\n",
    "\n",
    "An important aspect of geospatial data is that we can look at *spatial relationships*: how two spatial objects relate to each other (whether they overlap, intersect, contain, .. one another).\n",
    "\n",
    "The topological, set-theoretic relationships in GIS are typically based on the DE-9IM model. See https://en.wikipedia.org/wiki/Spatial_relation for more information.\n",
    "\n",
    "![](img/TopologicSpatialRelarions2.png)\n",
    "(Image by [Krauss, CC BY-SA 3.0](https://en.wikipedia.org/wiki/Spatial_relation#/media/File:TopologicSpatialRelarions2.png))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationships between individual objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create some small toy spatial objects:\n",
    "\n",
    "A polygon <small>(note: we use `.squeeze()` here to to extract the scalar geometry object from the GeoSeries of length 1)</small>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium = countries.loc[countries['name'] == 'Belgium', 'geometry'].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paris = cities.loc[cities['name'] == 'Paris', 'geometry'].squeeze()\n",
    "brussels = cities.loc[cities['name'] == 'Brussels', 'geometry'].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a linestring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString\n",
    "line = LineString([paris, brussels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize those 4 geometry objects together (I only put them in a GeoSeries to easily display them together with the geopandas `.plot()` method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopandas.GeoSeries([belgium, paris, brussels, line]).plot(cmap='tab10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can recognize the abstract shape of Belgium.\n",
    "\n",
    "Brussels, the capital of Belgium, is thus located within Belgium. This is a spatial relationship, and we can test this using the individual shapely geometry objects as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brussels.within(belgium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And using the reverse, Belgium contains Brussels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium.contains(brussels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, Paris is not located in Belgium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium.contains(paris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paris.within(belgium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The straight line we draw from Paris to Brussels is not fully located within Belgium, but it does intersect with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium.contains(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.intersects(belgium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial relationships with GeoDataFrames\n",
    "\n",
    "The same methods that are available on individual `shapely` geometries as we have seen above, are also available as methods on `GeoSeries` / `GeoDataFrame` objects.\n",
    "\n",
    "For example, if we call the `contains` method on the world dataset with the `paris` point, it will do this spatial check for each country in the `world` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.contains(paris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the above gives us a boolean result, we can use that to filter the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[countries.contains(paris)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed, France is the only country in the world in which Paris is located."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example, extracting the linestring of the Amazon river in South America, we can query through which countries the river flows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = rivers[rivers['name'] == 'Amazonas'].geometry.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[countries.crosses(amazon)]  # or .intersects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"font-size:120%\">\n",
    "<b>REFERENCE</b>: <br><br>\n",
    "\n",
    "Overview of the different functions to check spatial relationships (*spatial predicate functions*):\n",
    "\n",
    "* `equals`\n",
    "* `contains`\n",
    "* `crosses`\n",
    "* `disjoint`\n",
    "* `intersects`\n",
    "* `overlaps`\n",
    "* `touches`\n",
    "* `within`\n",
    "* `covers`\n",
    "\n",
    "\n",
    "See https://shapely.readthedocs.io/en/stable/manual.html#predicates-and-relationships for an overview of those methods.\n",
    "\n",
    "See https://en.wikipedia.org/wiki/DE-9IM for all details on the semantics of those operations.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's practice!\n",
    "\n",
    "We will again use the Paris datasets to do some exercises. Let's start importing them again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = geopandas.read_file(\"data/paris_districts_utm.geojson\")\n",
    "stations = geopandas.read_file(\"data/paris_sharing_bike_stations_utm.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>EXERCISE</b>:\n",
    "\n",
    "\n",
    "* Create a shapely `Point` object for the Notre Dame cathedral (which has x/y coordinates of (452321.4581477511, 5411311.330882619))\n",
    "* Calculate the distance of each bike station to the Notre Dame.\n",
    "* Check in which district the Notre Dame is located.\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/02-spatial-relationships-operations1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/02-spatial-relationships-operations2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/02-spatial-relationships-operations3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/02-spatial-relationships-operations4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial operations\n",
    "\n",
    "Next to the spatial predicates that return boolean values, Shapely and GeoPandas also provide operations that return new geometric objects.\n",
    "\n",
    "**Binary operations:**\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"img/spatial-operations-base.png\"/> </td>\n",
    "<td> <img src=\"img/spatial-operations-intersection.png\"/> </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td> <img src=\"img/spatial-operations-union.png\"/> </td>\n",
    "<td> <img src=\"img/spatial-operations-difference.png\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "**Buffer:**\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"img/spatial-operations-buffer-point1.png\"/> </td>\n",
    "<td> <img src=\"img/spatial-operations-buffer-point2.png\"/> </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td> <img src=\"img/spatial-operations-buffer-line.png\"/> </td>\n",
    "<td> <img src=\"img/spatial-operations-buffer-polygon.png\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "\n",
    "See https://shapely.readthedocs.io/en/stable/manual.html#spatial-analysis-methods for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, using the toy data from above, let's construct a buffer around Brussels (which returns a Polygon):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopandas.GeoSeries([belgium, brussels.buffer(1)]).plot(alpha=0.5, cmap='tab10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now take the intersection, union or difference of those two polygons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brussels.buffer(1).intersection(belgium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brussels.buffer(1).union(belgium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brussels.buffer(1).difference(belgium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful method is the `unary_union` attribute, which converts the set of geometry objects in a GeoDataFrame into a single geometry object by taking the union of all those geometries.\n",
    "\n",
    "For example, we can construct a single object for the Africa continent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_countries = countries[countries['continent'] == 'Africa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa = africa_countries.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(africa)[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"font-size:120%\">\n",
    "<b>REMEMBER</b>: <br><br>\n",
    "\n",
    "GeoPandas (and Shapely for the individual objects) provides a whole lot of basic methods to analyse the geospatial data (distance, length, centroid, boundary, convex_hull, simplify, transform, ....), much more than the few that we can touch in this tutorial.\n",
    "\n",
    "\n",
    "* An overview of all methods provided by GeoPandas can be found here: http://geopandas.readthedocs.io/en/latest/reference.html\n",
    "\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>EXERCISE: What are the districts close to the Seine?</b>\n",
    " \n",
    " <p>\n",
    " Below, the coordinates for the Seine river in the neighbourhood of Paris are provided as a GeoJSON-like feature dictionary (created at http://geojson.io). \n",
    " </p>\n",
    " \n",
    "  <p>\n",
    " Based on this `seine` object, we want to know which districts are located close (maximum 150 m) to the Seine. \n",
    " </p>\n",
    " \n",
    " \n",
    " <p>\n",
    " <ul>\n",
    "  <li>Create a buffer of 150 m around the Seine.</li>\n",
    "  <li>Check which districts intersect with this buffered object.</li>\n",
    "  <li>Make a visualization of the districts indicating which districts are located close to the Seine.</li>\n",
    " </ul> \n",
    " </p>\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created a line with http://geojson.io\n",
    "s_seine = geopandas.GeoDataFrame.from_features({\"type\":\"FeatureCollection\",\"features\":[{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"LineString\",\"coordinates\":[[2.408924102783203,48.805619828930226],[2.4092674255371094,48.81703747481909],[2.3927879333496094,48.82325391133874],[2.360687255859375,48.84912860497674],[2.338714599609375,48.85827758964043],[2.318115234375,48.8641501307046],[2.298717498779297,48.863246707697],[2.2913360595703125,48.859519915404825],[2.2594070434570312,48.8311646245967],[2.2436141967773438,48.82325391133874],[2.236919403076172,48.82347994904826],[2.227306365966797,48.828339513221444],[2.2224998474121094,48.83862215329593],[2.2254180908203125,48.84856379804802],[2.2240447998046875,48.85409863123821],[2.230224609375,48.867989496547864],[2.260265350341797,48.89192242750887],[2.300262451171875,48.910203080780285]]}}]},\n",
    "                                               crs={'init': 'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to local UTM zone\n",
    "s_seine_utm = s_seine.to_crs(epsg=32631)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "districts.plot(ax=ax, color='grey', alpha=0.4, edgecolor='k')\n",
    "s_seine_utm.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the single geometry object\n",
    "seine = s_seine_utm.geometry.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/02-spatial-relationships-operations5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/02-spatial-relationships-operations6.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/02-spatial-relationships-operations7.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/02-spatial-relationships-operations8.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Goals of this notebook:\n",
    "\n",
    "- Based on the `countries` and `cities` dataframes, determine for each city the country in which it is located.\n",
    "- To solve this problem, we will use the the concept of a 'spatial join' operation: combining information of geospatial datasets based on their spatial relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = geopandas.read_file(\"zip://./data/ne_110m_admin_0_countries.zip\")\n",
    "cities = geopandas.read_file(\"zip://./data/ne_110m_populated_places.zip\")\n",
    "rivers = geopandas.read_file(\"zip://./data/ne_50m_rivers_lake_centerlines.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap - joining dataframes\n",
    "\n",
    "Pandas provides functionality to join or merge dataframes in different ways, see https://chrisalbon.com/python/data_wrangling/pandas_join_merge_dataframe/ for an overview and https://pandas.pydata.org/pandas-docs/stable/merging.html for the full documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the concept of joining the information of two dataframes with pandas, let's take a small subset of our `cities` and `countries` datasets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities2 = cities[cities['name'].isin(['Bern', 'Brussels', 'London', 'Paris'])].copy()\n",
    "cities2['iso_a3'] = ['CHE', 'BEL', 'GBR', 'FRA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries2 = countries[['iso_a3', 'name', 'continent']]\n",
    "countries2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added a 'iso_a3' column to the `cities` dataset, indicating a code of the country of the city. This country code is also present in the `countries` dataset, which allows us to merge those two dataframes based on the common column.\n",
    "\n",
    "Joining the `cities` dataframe with `countries` will transfer extra information about the countries (the full name, the continent) to the `cities` dataframe, based on a common key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities2.merge(countries2, on='iso_a3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But**, for this illustrative example, we added the common column manually, it is not present in the original dataset. However, we can still know how to join those two datasets based on their spatial coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap - spatial relationships between objects\n",
    "\n",
    "In the previous notebook [02-spatial-relationships.ipynb](./02-spatial-relationships-operations.ipynb), we have seen the notion of spatial relationships between geometry objects: within, contains, intersects, ...\n",
    "\n",
    "In this case, we know that each of the cities is located *within* one of the countries, or the other way around that each country can *contain* multiple cities.\n",
    "\n",
    "We can test such relationships using the methods we have seen in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "france = countries.loc[countries['name'] == 'France', 'geometry'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.within(france)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above gives us a boolean series, indicating for each point in our `cities` dataframe whether it is located within the area of France or not.  \n",
    "Because this is a boolean series as result, we can use it to filter the original dataframe to only show those cities that are actually within France:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[cities.within(france)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now repeat the above analysis for each of the countries, and add a column to the `cities` dataframe indicating this country. However, that would be tedious to do manually, and is also exactly what the spatial join operation provides us.\n",
    "\n",
    "*(note: the above result is incorrect, but this is just because of the coarse-ness of the countries dataset)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Spatial join operation\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"font-size:120%\">\n",
    "    \n",
    "**SPATIAL JOIN** = *transferring attributes from one layer to another based on their spatial relationship* <br><br>\n",
    "\n",
    "\n",
    "Different parts of this operations:\n",
    "\n",
    "* The GeoDataFrame to which we want add information\n",
    "* The GeoDataFrame that contains the information we want to add\n",
    "* The spatial relationship we want to use to match both datasets ('intersects', 'contains', 'within')\n",
    "* The type of join: left or inner join\n",
    "\n",
    "\n",
    "![](img/illustration-spatial-join.svg)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In this case, we want to join the `cities` dataframe with the information of the `countries` dataframe, based on the spatial relationship between both datasets.\n",
    "\n",
    "We use the [`geopandas.sjoin`](http://geopandas.readthedocs.io/en/latest/reference/geopandas.sjoin.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = geopandas.sjoin(cities, countries, op='within', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined['continent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets's practice!\n",
    "\n",
    "We will again use the Paris datasets to do some exercises. Let's start importing them again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = geopandas.read_file(\"data/paris_districts_utm.geojson\")\n",
    "stations = geopandas.read_file(\"data/paris_sharing_bike_stations_utm.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>EXERCISE: Make a plot of the density of bike stations by district</b>\n",
    " <p>\n",
    " <ul>\n",
    "  <li>Determine for each bike station in which district it is located (using a spatial join!). Call the result `joined`.</li>\n",
    "  <li>Based on this result, calculate the number of bike stations in each district (e.g. using `groupby` method; you can use the `size` size method to know the size of each group).\n",
    "    <ul>\n",
    "      <li>Make sure the result is a DataFrame called `counts` with the columns 'district_name' and 'n_bike_stations'.</li>\n",
    "      <li>To go from a Series to a DataFrame, you can use the `reset_index` or `to_frame` method (both have a `name` keyword to specify a column name for the original Series values.\n",
    "    </ul>   \n",
    "   </li>\n",
    "  <li>Add those counts to the original `districts` dataframe, creating a new `districts2` dataframe (tip: this is a merge operation).</li>\n",
    "  <li>Calculate a new column 'n_bike_stations_by_area'.</li>\n",
    "  <li>Make a plot showing the density in bike stations of the districts.</li>  \n",
    " </ul> \n",
    " </p>\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/03-spatial-joins1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/03-spatial-joins2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/03-spatial-joins3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/03-spatial-joins4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/03-spatial-joins5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/03-spatial-joins6.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": true
   },
   "outputs": [],
   "source": [
    "# %load _solved/solutions/03-spatial-joins7.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The overlay operation\n",
    "\n",
    "In the spatial join operation above, we are not changing the geometries itself. We are not joining geometries, but joining attributes based on a spatial relationship between the geometries. This also means that the geometries need to at least overlap partially.\n",
    "\n",
    "If you want to create new geometries based on joining (combining) geometries of different dataframes into one new dataframe (eg by taking the intersection of the geometries), you want an **overlay** operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa = countries[countries['continent'] == 'Africa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities['geometry'] = cities.buffer(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopandas.overlay(africa, cities, how='difference').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"font-size:120%\">\n",
    "<b>REMEMBER</b> <br>\n",
    "\n",
    "* **Spatial join**: transfer attributes from one dataframe to another based on the spatial relationship\n",
    "* **Spatial overlay**: construct new geometries based on spatial operation between both dataframes (and combining attributes of both dataframes)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing spatial data with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = geopandas.read_file(\"zip://./data/ne_110m_admin_0_countries.zip\")\n",
    "cities = geopandas.read_file(\"zip://./data/ne_110m_populated_places.zip\")\n",
    "rivers = geopandas.read_file(\"zip://./data/ne_50m_rivers_lake_centerlines.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoPandas visualization functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting the figure size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.plot(figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the box / x and y coordinate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = countries.plot(figsize=(15, 15))\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coloring based on column values\n",
    "\n",
    "Let's first create a new column with the GDP per capita:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = countries[(countries['pop_est'] >0 ) & (countries['name'] != \"Antarctica\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries['gdp_per_cap'] = countries['gdp_md_est'] / countries['pop_est'] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now we can use this column to color the polygons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = countries.plot(figsize=(15, 15), column='gdp_per_cap')\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = countries.plot(figsize=(15, 15), column='gdp_per_cap', scheme='quantiles', legend=True)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining different dataframes on a single plot\n",
    "\n",
    "The `.plot` method returns a matplotlib Axes object, which can then be re-used to add additional layers to that plot with the `ax=` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = countries.plot(figsize=(15, 15))\n",
    "cities.plot(ax=ax, color='red', markersize=10)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = countries.plot(edgecolor='k', facecolor='none', figsize=(15, 10))\n",
    "rivers.plot(ax=ax)\n",
    "cities.plot(ax=ax, color='C1')\n",
    "ax.set(xlim=(-20, 60), ylim=(-40, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a background map with contextily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contextily package allow to easily add a web-tile based backgroubd (basemap) to your GeoPandas plots.\n",
    "\n",
    "Currently, the only requirement is that your data is already in the WebMercator projection (EPSG:3857)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the cities in Europe\n",
    "cities_europe = cities[cities.within(countries[countries['continent'] == 'Europe'].unary_union)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to WebMercator\n",
    "cities_europe2 = cities_europe.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = cities_europe2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = cities_europe2.plot(figsize=(10, 6))\n",
    "contextily.add_basemap(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = cities_europe2.plot(figsize=(10, 6))\n",
    "contextily.add_basemap(ax, url=contextily.sources.ST_TONER_LITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `geoplot`\n",
    "\n",
    "The `geoplot` packages provides some additional functionality compared to the basic `.plot()` method on GeoDataFrames:\n",
    "\n",
    "- High-level plotting API (with more plot types as geopandas)\n",
    "- Native projection support through cartopy\n",
    "\n",
    "https://residentmario.github.io/geoplot/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoplot\n",
    "import geoplot.crs as gcrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\n",
    "    'projection': gcrs.Orthographic(central_latitude=40.7128, central_longitude=-74.0059)\n",
    "})\n",
    "geoplot.choropleth(countries, hue='gdp_per_cap', projection=gcrs.Orthographic(), ax=ax,\n",
    "                   cmap='magma', linewidth=0.5, edgecolor='white', k=None)\n",
    "ax.set_global()\n",
    "ax.outline_patch.set_visible(True)\n",
    "#ax.coastlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `cartopy`\n",
    "\n",
    "Cartopy is the base matplotlib cartographic library, and it is used by `geoplot` under the hood to provide projection-awareness.\n",
    "\n",
    "http://scitools.org.uk/cartopy/docs/latest/index.html\n",
    "\n",
    "The following example is taken from the docs: http://geopandas.readthedocs.io/en/latest/gallery/cartopy_convert.html#sphx-glr-gallery-cartopy-convert-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cartopy import crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CartoPy CRS object.\n",
    "crs = ccrs.AlbersEqualArea()\n",
    "\n",
    "# This can be converted into a `proj4` string/dict compatible with GeoPandas\n",
    "crs_proj4 = crs.proj4_init\n",
    "countries_ae = countries.to_crs(crs_proj4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's what the plot looks like in GeoPandas\n",
    "countries_ae.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's what the plot looks like when plotting with cartopy\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': crs})\n",
    "ax.add_geometries(countries_ae['geometry'], crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's what the plot looks like when plotting with cartopy and geopandas combined\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': crs})\n",
    "countries_ae['geometry'].plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive web-based visualizations\n",
    "\n",
    "There are nowadays many libraries that target interactive web-based visualizations and that can handle geospatial data. Some packages with an example for each:\n",
    "\n",
    "- Bokeh: https://bokeh.pydata.org/en/latest/docs/gallery/texas.html\n",
    "- GeoViews (other interface to Bokeh/matplotlib): http://geo.holoviews.org\n",
    "- Altair: https://altair-viz.github.io/gallery/choropleth.html\n",
    "- Plotly: https://plot.ly/python/#maps\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular javascript library for online maps is [Leaflet.js](https://leafletjs.com/), and this has python bindings in the [folium](https://github.com/python-visualization/folium) and [ipyleaflet](https://github.com/jupyter-widgets/ipyleaflet) packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example with ipyleaflet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ipyleaflet.Map(center=[48.8566, 2.3429], zoom=6)\n",
    "\n",
    "layer = ipyleaflet.GeoJSON(data=cities.__geo_interface__)\n",
    "m.add_layer(layer)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ipyleaflet.Map(center=[48.8566, 2.3429], zoom=3)\n",
    "geo_data = ipyleaflet.GeoData(\n",
    "    geo_dataframe = countries,\n",
    "    style={'color': 'black', 'fillColor': '#3366cc', 'opacity':0.05, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.6},\n",
    "    hover_style={'fillColor': 'red' , 'fillOpacity': 0.2},\n",
    "    name = 'Countries')\n",
    "m.add_layer(geo_data)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More: https://ipyleaflet.readthedocs.io/en/latest/api_reference/geodata.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example with folium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map([48.8566, 2.3429], zoom_start=6, tiles=\"OpenStreetMap\")\n",
    "folium.GeoJson(countries).add_to(m)\n",
    "folium.GeoJson(cities).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map([0, 0], zoom_start=1)\n",
    "folium.Choropleth(geo_data=countries, data=countries, columns=['iso_a3', 'gdp_per_cap'],\n",
    "             key_on='feature.properties.iso_a3', fill_color='BuGn', highlight=True).add_to(m)\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
